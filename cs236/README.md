# CS236 - Deep Generative Models

I am independently studying Deep Generative Models using open-source materials provided by Stanford University and Cornell University. This repository documents my learning journey through this module, exploring the foundations and applications of generative models in AI and machine learning.

## Course Overview

Generative models are powerful tools used to model complex, high-dimensional data such as images, text, and speech. This course covers various types of generative models, including:

- Variational Autoencoders (VAEs)
- Generative Adversarial Networks (GANs)
- Autoregressive Models
- Normalizing Flows
- Energy-Based Models
- Score-Based Models

### Key Topics

- **Probabilistic Foundations**: Understanding the theoretical underpinnings of generative models.
- **Learning Algorithms**: Techniques for training and optimizing generative models.
- **Applications**: Exploring how generative models are applied in fields like computer vision, natural language processing, and reinforcement learning.

## Course Structure

The course consists of lectures, hands-on projects, and discussions. Key components include:

- **Lecture Attendance**: While in-person attendance is encouraged, recordings will be available on Canvas.
- **Assignments**: Three homework assignments, a midterm exam, and a course project.
- **Office Hours**: Available for additional support and clarification on course materials.

## Resources

### Lecture Notes and Materials

- [Deep Generative Models Course Website](https://deepgenerativemodels.github.io/)
- [Kuleshov Group DGM Website](https://kuleshov-group.github.io/dgm-website/)

### Recommended Reading

- "Deep Learning" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville (available [here](https://www.deeplearningbook.org/)).

## Prerequisites

To succeed in this course, students should have:

- Basic knowledge of machine learning (CS221, CS228, CS229, or CS230).
- Understanding of probabilities and calculus.
- Proficiency in Python programming.
